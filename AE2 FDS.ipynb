{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv(\"/Users/isaaclambert/Desktop/SST-2/train.tsv\", delimiter='\\t')\n",
    "dev = pd.read_csv(\"/Users/isaaclambert/Desktop/SST-2/dev.tsv\", delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the data\n",
    "The data is split psudeo-randomly into training and test sets using the train_test_split import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = reviews[\"sentence\"]\n",
    "y = reviews[\"label\"]\n",
    "\n",
    "# Randomly split the data into training and test sets\n",
    "train_x, test_x, train_y, test_y = split(x, y, test_size=0.25, random_state=21, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Vectorization\n",
    "Various configurations of text vectorization are tested. The results and analysis of these tests can be seen below. The TF-IDF approach forms the basis and the variables in question are: the use of stop words; the minimum document frequency (mdf) and the use and range of N-grams.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary with various text vectorizers + their descriptions as keys\n",
    "vectorizers = {'TF-IDF': TfidfVectorizer(), \n",
    "               'TF-IDF + no stop words': TfidfVectorizer(stop_words=\"english\"),\n",
    "               'TF-IDF + no stop words + mdf (5)': TfidfVectorizer(stop_words=\"english\", min_df=5),\n",
    "               'TF-IDF + no stop words + mdf (5) + N-grams (1-2)': TfidfVectorizer(stop_words=\"english\", min_df=5, ngram_range=(1,2)),\n",
    "               'TF-IDF + no stop words + mdf (2) + N-grams (1-2)': TfidfVectorizer(stop_words=\"english\", min_df=2, ngram_range=(1,2)),\n",
    "               'TF-IDF + no stop words + mdf (3) + N-grams (1-2)': TfidfVectorizer(stop_words=\"english\", min_df=3, ngram_range=(1,2)),\n",
    "               'TF-IDF + no stop words + mdf (2) + N-grams (1-3)': TfidfVectorizer(stop_words=\"english\", min_df=2, ngram_range=(1,3)),\n",
    "               'TF-IDF + mdf (2) + N-grams (1-2)': TfidfVectorizer(min_df=2, ngram_range=(1,2))\n",
    "              }\n",
    "\n",
    "# Create 2nd dictionary to display results  \n",
    "dic_to_df = {'Vectorizer':[], 'Number of features':[], 'Training accuracy':[], 'Test accuracy':[]}\n",
    "\n",
    "# Iterate through the 1st dictionary applying each type of vectorization to a Multinomial Naive Bayes model\n",
    "for i, ii in vectorizers.items():\n",
    "    \n",
    "    # Create the vocabulary based on the training data\n",
    "    ii.fit(train_x)\n",
    "    \n",
    "    # Based on the vocabulary\n",
    "    train_v = ii.transform(train_x)\n",
    "    test_v = ii.transform(test_x)\n",
    "    \n",
    "    # Train the model\n",
    "    model = MultinomialNB(alpha=0.5).fit(X=train_v, y=train_y)\n",
    "    \n",
    "    # Append results to 2nd dictionary \n",
    "    dic_to_df['Vectorizer'].append(i)\n",
    "    dic_to_df['Number of features'].append(len(ii.get_feature_names()))\n",
    "    dic_to_df['Training accuracy'].append(\"{:.2%}\".format(model.score(train_v, train_y)))\n",
    "    dic_to_df['Test accuracy'].append(\"{:.2%}\".format(model.score(test_v, test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>Number of features</th>\n",
       "      <th>Training accuracy</th>\n",
       "      <th>Test accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>13587</td>\n",
       "      <td>91.29%</td>\n",
       "      <td>88.24%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TF-IDF + no stop words</td>\n",
       "      <td>13305</td>\n",
       "      <td>90.37%</td>\n",
       "      <td>87.45%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TF-IDF + no stop words + mdf (5)</td>\n",
       "      <td>8758</td>\n",
       "      <td>88.46%</td>\n",
       "      <td>85.44%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TF-IDF + no stop words + mdf (5) + N-grams (1-2)</td>\n",
       "      <td>23844</td>\n",
       "      <td>90.32%</td>\n",
       "      <td>86.52%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TF-IDF + no stop words + mdf (2) + N-grams (1-2)</td>\n",
       "      <td>51521</td>\n",
       "      <td>93.65%</td>\n",
       "      <td>89.26%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TF-IDF + no stop words + mdf (3) + N-grams (1-2)</td>\n",
       "      <td>41558</td>\n",
       "      <td>92.76%</td>\n",
       "      <td>88.52%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TF-IDF + no stop words + mdf (2) + N-grams (1-3)</td>\n",
       "      <td>85157</td>\n",
       "      <td>94.08%</td>\n",
       "      <td>89.46%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TF-IDF + mdf (2) + N-grams (1-2)</td>\n",
       "      <td>68412</td>\n",
       "      <td>94.62%</td>\n",
       "      <td>89.96%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Vectorizer  Number of features  \\\n",
       "0                                            TF-IDF               13587   \n",
       "1                            TF-IDF + no stop words               13305   \n",
       "2                  TF-IDF + no stop words + mdf (5)                8758   \n",
       "3  TF-IDF + no stop words + mdf (5) + N-grams (1-2)               23844   \n",
       "4  TF-IDF + no stop words + mdf (2) + N-grams (1-2)               51521   \n",
       "5  TF-IDF + no stop words + mdf (3) + N-grams (1-2)               41558   \n",
       "6  TF-IDF + no stop words + mdf (2) + N-grams (1-3)               85157   \n",
       "7                  TF-IDF + mdf (2) + N-grams (1-2)               68412   \n",
       "\n",
       "  Training accuracy Test accuracy  \n",
       "0            91.29%        88.24%  \n",
       "1            90.37%        87.45%  \n",
       "2            88.46%        85.44%  \n",
       "3            90.32%        86.52%  \n",
       "4            93.65%        89.26%  \n",
       "5            92.76%        88.52%  \n",
       "6            94.08%        89.46%  \n",
       "7            94.62%        89.96%  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_vectorizer_results = pd.DataFrame.from_dict(dic_to_df)\n",
    "display(text_vectorizer_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anaylsis of vectorization alternatives\n",
    "The first 4 rows are generic configurations which are tested with a Multinomial Naive Bayes model. In conjunction they form an ablation study. This allows us to identify the impact of each addition. \n",
    "* From row 0 to 1: removing stop words decreases the amount of features marginally yet it  also decreases the test accuracy by almost a percent. \n",
    "* From row 1 to 2: it is clear that while the introduction of a mdf of 5 lowers the number of features, it also dramatically lowers the test accuracy, by just over 2%.\n",
    "* From row 2 to 3: the introduction of uni and bi-grams increases the number of features significantly but also increases the test accuracy by over a percent. \n",
    "* Since the mdf of 5 seems to have had a dramatic decrease in test accuracy, in row 4 it is decreased to 2. This leads to an increase of nearly 3% in test accuracy.\n",
    "* In row 5, the mdf is increased to 3 to see whether the increase in test accurancy can be maintained while reducing the number of features however since the test accuracy dops again I decided to keep the mdf at 2 in the subseqent rows. I did not test an mdf of 1 as I thought this would leave too many rare and sentiment unrelated words within the features. \n",
    "* In row 6 tri-grams are introducted. While doing so did increase the test accuracy by almost a percent it more than doubled the number of features. As such, I decided to keep a range of uni to bi-grams.\n",
    "* Finally, in row 7 the stop words which were removed are reintroduced. This does increase the number of features significantly, however, to less that the use of tri-grams did and it generates a test accuracy greater than the use of tri-grams - indeed the highest out of all tested permutations. I therefore used the configuration in line 7 to vectorize the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection - Cross-Validation \n",
    "Different models are tested using the Cross-Validation method. The models tested are: the multinomial Naive Bayes model used above; Descision Trees; and K-nearest neighbours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up cross-validation and pass number of folds\n",
    "cross_val = KFold(n_splits=10, random_state=21, shuffle=True)\n",
    "\n",
    "# Create 1st dictionary with the models to be tested + their descirptions as keys\n",
    "classifiers = {'MultinomialNB': MultinomialNB(),\n",
    "               'Descision Tree': DecisionTreeClassifier(),\n",
    "               'K-nearest neighbours': KNeighborsClassifier()\n",
    "              }\n",
    "\n",
    "# Create the vocabulary \n",
    "vectorizer = TfidfVectorizer(min_df=2, ngram_range=(1,2)).fit(train_x)\n",
    "\n",
    "# Based on the vocabulary, encode the words in the training and test dataset\n",
    "train_v = vectorizer.transform(train_x)\n",
    "test_v =vectorizer.transform(test_x)\n",
    "\n",
    "# Create 2nd dictionary to display results \n",
    "dic_to_df_2 = {'Model':[], 'Mean accuracy':[], 'Standard deviation':[]}\n",
    "\n",
    "for i, ii in classifiers.items():\n",
    "    # Cross-validate the models\n",
    "    results = cross_val_score(estimator=ii, X=train_v, y=train_y, cv=cross_val)\n",
    "    \n",
    "    # Append results to 2nd dictionary \n",
    "    dic_to_df_2['Model'].append(i)\n",
    "    dic_to_df_2['Mean accuracy'].append(\"{:.2%}\".format(results.mean()))\n",
    "    dic_to_df_2['Standard deviation'].append(\"{:.2%}\".format(results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean accuracy</th>\n",
       "      <th>Standard deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>90.17%</td>\n",
       "      <td>0.32%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Descision Tree</td>\n",
       "      <td>83.50%</td>\n",
       "      <td>0.67%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K-nearest neighbours</td>\n",
       "      <td>83.83%</td>\n",
       "      <td>0.56%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model Mean accuracy Standard deviation\n",
       "0         MultinomialNB        90.17%              0.32%\n",
       "1        Descision Tree        83.50%              0.67%\n",
       "2  K-nearest neighbours        83.83%              0.56%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diff_model_results = pd.DataFrame.from_dict(dic_to_df_2)\n",
    "display(diff_model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of model testing results\n",
    "* The Multinomial Naive Bayes model has the highest test accuracy by far as well as the lowest standard deviation. As such, it is the clear winner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-parameter turning - Grid Search\n",
    "In order to find the optimum values for the parameters and/or hyper-parameters, the Grid Seach method is used on the multinomial Naive Bayes model. In the first cell the paramaters and their default values for this modle are printed. In the second Grid Search is intialized with a range of values for alpha. Finally the results of the Grid Search are printed in the terminal of the third cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1.0, 'class_prior': None, 'fit_prior': True}\n"
     ]
    }
   ],
   "source": [
    "# Show hyper-parameters for this type of model\n",
    "print(MultinomialNB().get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "best_model = MultinomialNB()\n",
    "\n",
    "# Set the possible values for hyper-parameter \n",
    "alphas = np.array([1, 0.75, 0.55, 0.5, 0.45, 0.25, 0.1, 0.01, 0.001])\n",
    "\n",
    "# Set up grid search and fit it to the data \n",
    "grid = GridSearchCV(estimator=best_model, param_grid=dict(alpha=alphas))\n",
    "grid.fit(X=train_v, y=train_y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value for {'alpha': 0.5}\n",
      "Best training accuracy: 90.04%\n",
      "Test accuracy: 89.96%\n"
     ]
    }
   ],
   "source": [
    "print(f'Best value for {grid.best_params_}')\n",
    "print(f'Best training accuracy: {grid.best_score_:.2%}')\n",
    "print(f'Test accuracy: {grid.score(test_v, test_y):.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Grid Search results\n",
    "* Since the optimum value of alpha is 0.5 and the adjacent bounds are only 0.05 away, no further values need to be tested and 0.5 can be input into the multinomial naive bayes model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the final model\n",
    "The best type of model for this task is trained with the optimum value of alpha with text which has been vectorized in the best way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_tuned = MultinomialNB(alpha=0.5)\n",
    "best_model_tuned_fitted = MultinomialNB(alpha=0.5).fit(X=train_v, y=train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dev.tsv dataset Test \n",
    "Finally, the model is tested on the unseen dev.tsv dataset and the resutls are printed in the terminal below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models accuracy on dev.tsv dataset: 81.77%\n"
     ]
    }
   ],
   "source": [
    "dev_x = dev[\"sentence\"]\n",
    "dev_y = dev[\"label\"]\n",
    "\n",
    "# Encode the words from the dev.tsv dataset\n",
    "dev_v = vectorizer.transform(dev_x)\n",
    "\n",
    "print(f'Models accuracy on dev.tsv dataset: {best_model_tuned_fitted.score(dev_v, dev_y):.2%}')     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethical Reflections \n",
    "Since machine learning models of this sort are never 100% accurate yet often used to make predictions or as the basis for imporant descisions, it is essential to be completely transparent about their limitations and the types of mistake they can make. To this end, it can be helpful to make a confusion matrix and see what types of text were misclassified and why. Likewise since the data to train such models can often be obtained in unscrupulous ways being transparent about what the source of one's data is ethically important. For this model the publically accessible Standford Sentiment Treebank dataset was used.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "* Text Vectorization/Ablation Study, Text Analytics Notebook, Alexandros Koliousis, 22/04/21\n",
    "* Cross-Validation, Machine Learning applications Notebook, Alexandros Koliousis, 22/04/21\n",
    "* [Grid Search, Jason Brownlee, 23/04/21](https://machinelearningmastery.com/how-to-tune-algorithm-parameters-with-scikit-learn/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
